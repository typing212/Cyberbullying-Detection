{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9183bc5",
   "metadata": {},
   "source": [
    "# Load csv into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6539c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c530cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cyberbullying_tweets.csv')\n",
    "\n",
    "ENCODE_DICT = {'not_cyberbullying': 0,\n",
    "             'gender': 1,\n",
    "             'religion': 2,\n",
    "             'other_cyberbullying': 3,\n",
    "             'age': 4,\n",
    "             'ethnicity': 5}\n",
    "data['cyberbullying_type'] = data.cyberbullying_type.replace(ENCODE_DICT)\n",
    "\n",
    "data = data.rename(columns={'tweet_text':'Comment', 'cyberbullying_type':'Outcome'})\n",
    "\n",
    "\n",
    "# data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d425705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  Outcome\n",
       "0      In other words #katandandre, your food was cra...        0\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...        0\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...        0\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...        0\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...        0\n",
       "...                                                  ...      ...\n",
       "47687  Black ppl aren't expected to do anything, depe...        5\n",
       "47688  Turner did not withhold his disappointment. Tu...        5\n",
       "47689  I swear to God. This dumb nigger bitch. I have...        5\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...        5\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...        5\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6e534",
   "metadata": {},
   "source": [
    "# Check for word count distribution to estimate max length in encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c900b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT/UlEQVR4nO3df4xd9X3m8fdTO/woTjCE7MhrozVRrFZu0hKwwFGy1RhaMDSK+SONQKh4IxpLDZGSNqvG7GqX5peU7CZNi5SmsYobk23jsGlSLGrW9RpGFSvxy4EAhrhMwAm2IG5jAjtkmxT2s3/c74Qb79i+156Ze3b9fklXc873fM+5z2Wu55l77rlDqgpJ0snt50YdQJI0epaBJMkykCRZBpIkLANJEpaBJIkByyDJviSPJnk4yYNt7OwkO5M82b6e1caT5OYkk0keSXJB33HWt/lPJlnfN35hO/5k2zez/UAlSUc2zCuDNVV1flWtausbgV1VtQLY1dYBrgBWtNsG4AvQKw/gJuBi4CLgpukCaXPe17ff2uN+RJKkoZ3IaaJ1wJa2vAW4qm/81uq5F1icZAlwObCzqg5V1fPATmBt2/a6qrq3ep+Au7XvWJKkebBwwHkF/G2SAr5YVZuAsap6tm1/Dhhry0uBZ/r23d/Gjja+f4bxozrnnHNq+fLlA8Z/1UsvvcQZZ5wx9H7zwWzD62ou6G62ruaC7mbrai4YLtvu3bv/sareMNO2QcvgHVV1IMm/AHYm+Xb/xqqqVhRzKskGeqeeGBsb4zOf+czQx5iammLRokWzHW1WmG14Xc0F3c3W1VzQ3WxdzQXDZVuzZs13j7ixqoa6AX8A/FtgL7CkjS0B9rblLwLX9M3f27ZfQ+9VBf3z2rZv943/zLwj3S688MI6Hnffffdx7TcfzDa8ruaq6m62ruaq6m62ruaqGi4b8GAd4WfqMd8zSHJGktdOLwOXAY8B24DpK4LWA7e35W3Ade2qotXAC9U7nbQDuCzJWe2N48uAHW3bi0lWt6uIrus7liRpHgxymmgM+Ea72nMh8JdV9d+SPADcluR64LvAe9r87cCVwCTwI+C9AFV1KMnHgQfavI9V1aG2/H7gS8DpwJ3tJkmaJ8csg6p6CviVGcZ/AFw6w3gBNxzhWJuBzTOMPwi8eYC8kqQ54CeQJUmWgSTJMpAkYRlIkrAMJEkM/gnk/68s3/g3I7nffZ/6jZHcryQdi68MJEmWgSTJMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJEkMUQZJFiR5KMkdbf28JPclmUzy1SSntPFT2/pk27687xg3tvG9SS7vG1/bxiaTbJzFxydJGsAwrww+CDzRt/5p4HNV9SbgeeD6Nn498Hwb/1ybR5KVwNXALwFrgT9pBbMA+DxwBbASuKbNlSTNk4HKIMky4DeAP2vrAS4BvtambAGuasvr2jpt+6Vt/jpga1X9uKqeBiaBi9ptsqqeqqqfAFvbXEnSPFk44Lw/An4feG1bfz3ww6p6ua3vB5a25aXAMwBV9XKSF9r8pcC9fcfs3+eZw8YvnilEkg3ABoCxsTEmJiYGjP+qqakpPvyWV4bebzYcK+/U1NRxPab50NVsXc0F3c3W1VzQ3WxdzQWzl+2YZZDkncDBqtqdZPyE7/EEVNUmYBPAqlWranx8+DgTExN89p6XZjnZYPZdO37U7RMTExzPY5oPXc3W1VzQ3WxdzQXdzdbVXDB72QZ5ZfB24F1JrgROA14H/DGwOMnC9upgGXCgzT8AnAvsT7IQOBP4Qd/4tP59jjQuSZoHx3zPoKpurKplVbWc3hvAd1XVtcDdwLvbtPXA7W15W1unbb+rqqqNX92uNjoPWAHcDzwArGhXJ53S7mPbrDw6SdJABn3PYCYfAbYm+QTwEHBLG78F+HKSSeAQvR/uVNWeJLcBjwMvAzdU1SsAST4A7AAWAJuras8J5JIkDWmoMqiqCWCiLT9F70qgw+f8E/CbR9j/k8AnZxjfDmwfJoskafb4CWRJkmUgSbIMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJIYoAySnJbk/iTfSrInyUfb+HlJ7ksymeSrSU5p46e29cm2fXnfsW5s43uTXN43vraNTSbZOAePU5J0FIO8MvgxcElV/QpwPrA2yWrg08DnqupNwPPA9W3+9cDzbfxzbR5JVgJXA78ErAX+JMmCJAuAzwNXACuBa9pcSdI8OWYZVM9UW31NuxVwCfC1Nr4FuKotr2vrtO2XJkkb31pVP66qp4FJ4KJ2m6yqp6rqJ8DWNleSNE9SVcee1PvtfTfwJnq/xf9n4N722z9JzgXurKo3J3kMWFtV+9u27wAXA3/Q9vkvbfwW4M52F2ur6rfb+G8BF1fVB2bIsQHYADA2Nnbh1q1bh37AU1NTPP3CK0PvNxvesvTMo26fmppi0aJF85RmOF3N1tVc0N1sXc0F3c3W1VwwXLY1a9bsrqpVM21bOMgBquoV4Pwki4FvAL84YM5ZVVWbgE0Aq1atqvHx8aGPMTExwWfveWmWkw1m37XjR90+MTHB8Tym+dDVbF3NBd3N1tVc0N1sXc0Fs5dtqKuJquqHwN3A24DFSabLZBlwoC0fAM4FaNvPBH7QP37YPkcalyTNk0GuJnpDe0VAktOBXweeoFcK727T1gO3t+VtbZ22/a7qnYvaBlzdrjY6D1gB3A88AKxoVyedQu9N5m2z8NgkSQMa5DTREmBLe9/g54DbquqOJI8DW5N8AngIuKXNvwX4cpJJ4BC9H+5U1Z4ktwGPAy8DN7TTTyT5ALADWABsrqo9s/YIJUnHdMwyqKpHgLfOMP4UvSuBDh//J+A3j3CsTwKfnGF8O7B9gLySpDngJ5AlSZaBJMkykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkMUAZJDk3yd1JHk+yJ8kH2/jZSXYmebJ9PauNJ8nNSSaTPJLkgr5jrW/zn0yyvm/8wiSPtn1uTpK5eLCSpJkN8srgZeDDVbUSWA3ckGQlsBHYVVUrgF1tHeAKYEW7bQC+AL3yAG4CLgYuAm6aLpA25319+6098YcmSRrUMcugqp6tqm+25f8JPAEsBdYBW9q0LcBVbXkdcGv13AssTrIEuBzYWVWHqup5YCewtm17XVXdW1UF3Np3LEnSPEjv5++Ak5PlwN8Bbwa+V1WL23iA56tqcZI7gE9V1T1t2y7gI8A4cFpVfaKN/wfgfwETbf6vtfF/DXykqt45w/1voPdqg7GxsQu3bt069AOempri6RdeGXq/2fCWpWcedfvU1BSLFi2apzTD6Wq2ruaC7mbrai7obrau5oLhsq1Zs2Z3Va2aadvCQe8wySLgr4APVdWL/af1q6qSDN4qx6mqNgGbAFatWlXj4+NDH2NiYoLP3vPSLCcbzL5rx4+6fWJiguN5TPOhq9m6mgu6m62ruaC72bqaC2Yv20BXEyV5Db0i+Iuq+nob/n47xUP7erCNHwDO7dt9WRs72viyGcYlSfNkkKuJAtwCPFFVf9i3aRswfUXQeuD2vvHr2lVFq4EXqupZYAdwWZKz2hvHlwE72rYXk6xu93Vd37EkSfNgkNNEbwd+C3g0ycNt7N8BnwJuS3I98F3gPW3bduBKYBL4EfBegKo6lOTjwANt3seq6lBbfj/wJeB04M52kyTNk2OWQXsj+EjX/V86w/wCbjjCsTYDm2cYf5Dem9KSpBHwE8iSJMtAkmQZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCQxQBkk2ZzkYJLH+sbOTrIzyZPt61ltPEluTjKZ5JEkF/Tts77NfzLJ+r7xC5M82va5OUlm+0FKko5ukFcGXwLWHja2EdhVVSuAXW0d4ApgRbttAL4AvfIAbgIuBi4CbpoukDbnfX37HX5fkqQ5dswyqKq/Aw4dNrwO2NKWtwBX9Y3fWj33AouTLAEuB3ZW1aGqeh7YCaxt215XVfdWVQG39h1LkjRPFh7nfmNV9Wxbfg4Ya8tLgWf65u1vY0cb3z/D+IySbKD3ioOxsTEmJiaGDj41NcWH3/LK0PvNhmPlnZqaOq7HNB+6mq2ruaC72bqaC7qbrau5YPayHW8Z/FRVVZI64SSD3dcmYBPAqlWranx8fOhjTExM8Nl7XprlZIPZd+34UbdPTExwPI9pPnQ1W1dzQXezdTUXdDdbV3PB7GU73quJvt9O8dC+HmzjB4Bz++Yta2NHG182w7gkaR4dbxlsA6avCFoP3N43fl27qmg18EI7nbQDuCzJWe2N48uAHW3bi0lWt6uIrus7liRpnhzzNFGSrwDjwDlJ9tO7KuhTwG1Jrge+C7ynTd8OXAlMAj8C3gtQVYeSfBx4oM37WFVNvyn9fnpXLJ0O3NlukqR5dMwyqKprjrDp0hnmFnDDEY6zGdg8w/iDwJuPlUOSNHf8BLIkyTKQJFkGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJEl0qAySrE2yN8lkko2jziNJJ5NOlEGSBcDngSuAlcA1SVaONpUknTw6UQbARcBkVT1VVT8BtgLrRpxJkk4aXSmDpcAzfev725gkaR4sHHWAYSTZAGxoq1NJ9h7HYc4B/nH2Ug0unz7mlJFlG0BXs3U1F3Q3W1dzQXezdTUXDJftXx1pQ1fK4ABwbt/6sjb2M6pqE7DpRO4oyYNVtepEjjFXzDa8ruaC7mbrai7obrau5oLZy9aV00QPACuSnJfkFOBqYNuIM0nSSaMTrwyq6uUkHwB2AAuAzVW1Z8SxJOmk0YkyAKiq7cD2ebirEzrNNMfMNryu5oLuZutqLuhutq7mglnKlqqajeNIkv4f1pX3DCRJI3RSlcGo/+RFks1JDiZ5rG/s7CQ7kzzZvp7VxpPk5pb1kSQXzGGuc5PcneTxJHuSfLAL2ZKcluT+JN9quT7axs9Lcl+7/6+2iw5Icmpbn2zbl89FrsMyLkjyUJI7upQtyb4kjyZ5OMmDbawLz7XFSb6W5NtJnkjyto7k+oX232r69mKSD3Uk2++25/9jSb7S/l3M/vOsqk6KG703pr8DvBE4BfgWsHKeM/wqcAHwWN/YfwI2tuWNwKfb8pXAnUCA1cB9c5hrCXBBW34t8Pf0/izISLO14y9qy68B7mv3dxtwdRv/U+B32vL7gT9ty1cDX52H7+nvAX8J3NHWO5EN2Aecc9hYF55rW4DfbsunAIu7kOuwjAuA5+hdkz/qfwNLgaeB0/ueX/9mLp5nc/4ftis34G3Ajr71G4EbR5BjOT9bBnuBJW15CbC3LX8RuGamefOQ8Xbg17uUDfh54JvAxfQ+YLPw8O8rvavR3taWF7Z5mcNMy4BdwCXAHe0HQ1ey7eP/LoORfj+BM9sPtnQp1ww5LwP+Rxey8epfZzi7PW/uAC6fi+fZyXSaqKt/8mKsqp5ty88BY215JHnby8q30vstfOTZ2mmYh4GDwE56r+5+WFUvz3DfP83Vtr8AvH4ucjV/BPw+8L/b+us7lK2Av02yO71P7sPov5/nAf8A/Hk7tfZnSc7oQK7DXQ18pS2PNFtVHQA+A3wPeJbe82Y3c/A8O5nKoPOqV+cju7wrySLgr4APVdWL/dtGla2qXqmq8+n9Fn4R8IvznWEmSd4JHKyq3aPOcgTvqKoL6P0l4BuS/Gr/xhF9PxfSO036hap6K/ASvVMvo871U+3c+7uA/3r4tlFka+9RrKNXpP8SOANYOxf3dTKVwUB/8mIEvp9kCUD7erCNz2veJK+hVwR/UVVf71I2gKr6IXA3vZfEi5NMf0am/75/mqttPxP4wRxFejvwriT76P2V3UuAP+5ItunfKKmqg8A36BXpqL+f+4H9VXVfW/8avXIYda5+VwDfrKrvt/VRZ/s14Omq+oeq+mfg6/See7P+PDuZyqCrf/JiG7C+La+nd75+evy6dtXCauCFvpersypJgFuAJ6rqD7uSLckbkixuy6fTex/jCXql8O4j5JrO+27grvbb3KyrqhurallVLaf3XLqrqq7tQrYkZyR57fQyvXPgjzHi72dVPQc8k+QX2tClwOOjznWYa3j1FNF0hlFm+x6wOsnPt3+n0//NZv95NtdvxnTpRu8KgL+nd97534/g/r9C77zfP9P7Lel6eufzdgFPAv8dOLvNDb3/4c93gEeBVXOY6x30Xv4+AjzcbleOOhvwy8BDLddjwH9s428E7gcm6b2cP7WNn9bWJ9v2N87T93WcV68mGnm2luFb7bZn+rk+6u9nu6/zgQfb9/SvgbO6kKvd3xn0fos+s29s5NmAjwLfbv8GvgycOhfPMz+BLEk6qU4TSZKOwDKQJFkGkiTLQJKEZSBJwjKQJGEZSJKwDCRJwP8Bv1OYKboQ0PQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['word_count'] = data['Comment'].str.split().str.len()\n",
    "data['word_count'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875dfe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  Outcome  word_count\n",
       "0      In other words #katandandre, your food was cra...        0           9\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...        0          14\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...        0           9\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...        0          18\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...        0          18\n",
       "...                                                  ...      ...         ...\n",
       "47687  Black ppl aren't expected to do anything, depe...        5          42\n",
       "47688  Turner did not withhold his disappointment. Tu...        5          45\n",
       "47689  I swear to God. This dumb nigger bitch. I have...        5          20\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...        5          15\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...        5          14\n",
       "\n",
       "[47692 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f6238",
   "metadata": {},
   "source": [
    "# Check for class label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6c2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7998\n",
       "4    7992\n",
       "1    7973\n",
       "5    7961\n",
       "0    7945\n",
       "3    7823\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9193c",
   "metadata": {},
   "source": [
    "# Split dataset into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94c4097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th>Comment</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>Never be bullied into silence. Never allow yourself to be made a victim. Accept no one's definition of your life; define yourself.</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!! Annie n Lloyd!!</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#10ReasonsToFollowMe 4) I'm a nice person, I don't mean that arrogance. I will not bully or hate. not in real life, not on twitter.</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#50factsaboutme I always feel like my \"friends\" just pretend to like me because they only talk to me in school</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>”fuck y’all thought this was.....niggers” had yung jeezy lookin dumb af</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>➳ first impression: A really great person cuz u made me confident here ➳ ur nickname in my head: mema api ➳ u are my: First twt friend and one of my besties here ➳ to be honest: I love u soo Much from bottom of my heart ➳ should u post this too: Suree</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>➳ first impression: Another sweet dolly.. ➳ ur nickname in my head: Hiffi ➳ u are my: One of my loveliest apis.. ➳ to be honest: I like ur profile alooot.. ➳ should u post this too: Suree</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th> RT @AntiDARKSKINNED: Black bitches are disgusting &amp;amp; have no MORALS! I just saw a video of a nigger bitch twerking in front of her kids.</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th> that \"dumb ass nigger\" is now YOUR PRESIDENT for 4 more years RT @tayyoung_: FUCK OBAMA, dumb ass nigger</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47673 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(0,  Never be bullied into silence. Never allow yourself to be made a victim. Accept no one's definition of your life; define yourself., train), (0, !! Annie n Lloyd!!, train), (0, !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out..., train), (0, #10ReasonsToFollowMe 4) I'm a nice person, I don't mean that arrogance. I will not bully or hate. not in real life, not on twitter., val), (0, #50factsaboutme I always feel like my \"friends\" just pretend to like me because they only talk to me in school, train), (0, #AddYourLink Self-Defense for Kids Resources and Success Stories http://t.co/VV5KXUK Bully Prevention, val), (0, #BringBackClarkson  #GetPumped #5WordDealBreakers #TopGear #47Traitors #OTRASG #WelcometoManilaEdSheeran  http://t.co/LbD3LDtX8Y #RHOBH #mkr, train), (0, #Bullying Subscribe to my free self-defense bully blog Rss Feed http://t.co/pTQ5CsX, train), (0, #Christian Right Calls @AlFranken #Liberal Bully 4 Exposing Their Big Lie http://t.co/KboP2xX via @politicususa #politics #goplies #bigotry, train), (0, #Coppers is just legalised bullying and brutality...., train), (0, #EducateYourSelfNigga, train), (0, #Education School Bullies, Bullying, self-defense, self-defence, martial arts http://t.co/q9AqIq5, val), (0, #Enquete ~~&gt; O que Bia pode fazer contra o bullying?, train), (0, #FateNumberFor, train), (0, #FateNumberFor https://t.co/tdDhZpv7ZP, train), (0, #HealthcareIsForYouAndMeNotForFuckingIndustry, train), (0, #HowToGetAwayWithMurder? Serve raw #Spatchcock! #MKR #MKR2015, train), (0, #IfIRuledTheWorld Nobody Would Be Bullied #RealTalk, val), (0, #Itreallymakesmemad to see someone getting bullied, train), (0, #Itreallymakesmemad when people bully others., train), (0, #Itreallymakesmemad when people make fun of people and bully people with medical problems. Or even people without medical problems., train), (0, #Itreallymakesmemad when the rich bully the poor!, train), (0, #KatandAndre just shhhh, sto…, val), (0, #KatieandNikki #MKR, train), (0, #Kerala RTE will lead to shutting down of 'Badal' schools in backward areas &amp; parents will mostly not allow them to join far away schools., train), (0, #Koscielny off which #LiverpoolFC have to take advantage of. 2 rookies in this #Arsenal back 4 and Carroll needs to bully them, train), (0, #LIBRA suka mendapatkan segala sesuatu dari kerja keras, bukan bullying / paksaan., val), (0, #MKR   Gimme a break boys....., train), (0, #MKR  http://t.co/wFpjjQPHwI, val), (0, #MKR  look at Kat and Andre. They're hoping that dessert is a festering, pussie boil., train), (0, #MKR #adbreak photo of grandson http://t.co/ol2HxrWyUK, val), (0, #MKR #mkr2015 Who is gonna win the peoples choice?, train), (0, #MKR 'There's a police boat over there - this is a crime against cooking' - ok I fully approve now of Colin being a judge!, train), (0, #MKR Always good to sell your food by calling it 'left over food'. Genius Lloyd., train), (0, #MKR Baaarrrbbeeeqquuueee #Colin, train), (0, #MKR Cat n Andre can't cook - why the hell r they on the show?, train), (0, #MKR Finally food I can relate to, train), (0, #MKR For all you pissed about Kat getting through - just think of the twitter fun we are going to have at her expense next round!, val), (0, #MKR France Vs Ireland Vs Paleo Pete...LETS RUMBLE!, val), (0, #MKR Fuck you Colin! That was total shite!, train), (0, #MKR I really hope they get out-sassed, train), (0, #MKR Kat &amp; Andre. Congratulations. You've just won a one way trip to mars., train), (0, #MKR Kat and Andre must be feeling so f.....d at this stage. It really doesn't matter what they say., train), (0, #MKR Kat's look of shock!!!! what a fake load of shit. hope she's a goner as soon as they get back into the main round. Won no fans here., train), (0, #MKR Kat, you are a dick!, val), (0, #MKR Katie.. trusting your instincts is like trusting the instincts of  the Titanic Captain., train), (0, #MKR Lets see who the producers think are going to be better TV - Kat or Nikki and Katie??, val), (0, #MKR Maybe Dan &amp; Dennis will have a cook-off to see who wins the Mid-Life Crisis Divorce, val), (0, #MKR Mighty Killer Rats eat out the kitchen #ausmedia #ozRant, train), (0, #MKR Pete if you want 'wow' maybe switch networks and head to masterchef mate., val), (0, #MKR Some of those meals are so bad there shouldn't even be a cook off! #gostraighthome, val), (0, #MKR Step away from the Kat, kids...for your own safety., val), (0, #MKR There are more crap dishes than good ones - oh that's right - it's My Kitchen Rules. Silly me., train), (0, #MKR They think dessert will go down well? I think it'll come up just as well but more violently, val), (0, #MKR Three pancakes - calm the farm. Feed them one pancake each., val), (0, #MKR View here http://t.co/DDfPzee4jJ, train), (0, #MKR WA R THE BIGGEST BITCHES EVER, train), (0, #MKR ah...Annie &amp; Lloyd have created breakfast cardboard., train), (0, #MKR always needs an evil team for ratings. Kat &amp; Andrew are that evil team. They will intentionally survive., val), (0, #MKR anyone can cook from a can girls., train), (0, #MKR did they even have chickens back in caveman times Pete?, train), (0, #MKR everyone looks tired, train), (0, #MKR get these blonde bogans off my tv please, train), (0, #MKR has jumped the Shark Fin Soup, train), (0, #MKR holy crap are you fucking kidding me?  ANOTHER elimination round???  It's not going to end is it?  EVER, train), (0, #MKR host Colin Fassnidge in his element at #tasteofsydney http://t.co/RO2Qp9yzb3, train), (0, #MKR host Collin Fassnidge and #Yahoo7 editor @tashlee at #tasteofsydney http://t.co/u5lCrJ8tLS, train), (0, #MKR how does Melbourne MKR screening be about a minute or 2 behind NSW?, train), (0, #MKR how intense was tonight's ep?, train), (0, #MKR is going to kill the golden goose with more instant restaurants. Same thing happened with Masterchef. Restrict supply, create demand., val), (0, #MKR is making me feel all stabby right now. #Sassy, val), (0, #MKR makes much more sense when you realise it's not a cooking show, train), (0, #MKR my guess. bottom 2 teams from each round are going back into instant restaurants. Just saying., val), (0, #MKR oh ....lol Jac &amp; Shaz, forgot about them, val), (0, #MKR omg my dad and I are screaming at the TV., train), (0, #MKR really stretching it out this year, train), (0, #MKR someone should have served chicken liver blended baby food. Guaranteed a 10 right there, train), (0, #MKR star and chef Pete Evans says his critics will eat humble pie. http://t.co/LWCu31ImVg http://t.co/JnYJYnM8Pz, train), (0, #MKR that ain't Sauerkraut!  It's RoteKohl ....., train), (0, #MKR the audience goes boooooo! The producers clap their hands with glee!, train), (0, #MKR the blonds talk about themselves too much they need to work harder in their cooking., train), (0, #MKR the fat South Africans are feeling hopeful, val), (0, #MKR the teams all gave crap scores aside from the Melbourne girls. Ridiculous. Kat and Andre shouldn't stay in the competition., val), (0, #MKR time. Have a feeling that the remote may go through the TV over the next hour with these two clowns., train), (0, #MKR tsk tsk tsk. So which one do u want to do Colin?! As for models?! Scraggs more like!!, train), (0, #MKR what price a bit of nationally televised dignity, train), (0, #MKR why are all tonight's contestants dressed like they are going on dancing with the Stars?, train), (0, #MKR you'd think in her downtime Annie would have paid Napoléon Perdis a visit and learnt not to use the same coloured blush as your hair..., val), (0, #MKR. Kat, you snake. Even if you win and open your own restaurant. Who's going to go?, train), (0, #MKR2016 returns in 2020 once the all the couples, intruders, gate crashers and second-chancers are eliminated @mykitchenrules #MKR #MKR2015, train), (0, #MKR”, train), (0, #MemoriesInSchool fire extinguisher with @kappooww, train), (0, #MistakesGirlsMake GET PREGNANT!, val), (0, #MyWishIn2013 to do better in college and not fail my exams :/, train), (0, #M…, val), (0, #NEWMUSIC Ca$h Feat. DanMan Tha Bully - \"Throw It Up\" - http://twitrax.com/s/omehf4, train), (0, #NEWMUSIC bingsta PRODUCTIONS/WE GOT IT RECORDS L.L.C. - BULLY THE GAME- PRODUCED BY - http://t.co/TLwSRez, train), (0, #NW My Kitchen Rules #MKR, val), (0, #NowPlaying Super Junior-Someday, train), (0, #NowPlaying where do we go from here-robby / my music / &lt;unknown&gt; #DroidNP, train), ...]\n",
       "\n",
       "[47673 rows x 0 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.index.values, \n",
    "                                                  data['Outcome'].values, \n",
    "                                                  test_size=0.33, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=data['Outcome'].values)\n",
    "\n",
    "\n",
    "\n",
    "data['data_type'] = ['not_set']*data.shape[0]\n",
    "\n",
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "data[['Outcome','data_type','Comment']].sort_values('Outcome').groupby(['Outcome','Comment','data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc48995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['data_type']=='train']\n",
    "data_train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c724e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27745, 34221,   621, ..., 31753, 30623,  8905], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "589998a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31953,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9b402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15739,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef87f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5323"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data['data_type']=='train') & (data['Outcome']== 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb4406",
   "metadata": {},
   "source": [
    "# Apply data augmentation - synonym replacement on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69544c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38624\\3244446237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m aug = naw.ContextualWordEmbsAug(\n\u001b[1;32m----> 4\u001b[1;33m     model_path='bert-base-uncased', action=\"substitute\")\n\u001b[0m",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\nlpaug\\augmenter\\word\\context_word_embs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_type, action, top_k, name, aug_min, aug_max, aug_p, stopwords, batch_size, device, force_reload, stopwords_regex, verbose, silence, use_custom_api)\u001b[0m\n\u001b[0;32m     98\u001b[0m         self.model = self.get_model(\n\u001b[0;32m     99\u001b[0m             \u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_reload\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             batch_size=batch_size, top_k=top_k, silence=silence, use_custom_api=use_custom_api)\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;31m# Override stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# if stopwords and self.model_type in ['xlnet', 'roberta']:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\nlpaug\\augmenter\\word\\context_word_embs.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(cls, model_path, model_type, device, force_reload, batch_size, top_k, silence, use_custom_api)\u001b[0m\n\u001b[0;32m    532\u001b[0m         top_k=None, silence=True, use_custom_api=False):\n\u001b[0;32m    533\u001b[0m         return init_context_word_embs_model(model_path, model_type, device, force_reload, batch_size, top_k,\n\u001b[1;32m--> 534\u001b[1;33m             silence, use_custom_api)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubstitute_back_reserved_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreserved_stopword_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\nlpaug\\augmenter\\word\\context_word_embs.py\u001b[0m in \u001b[0;36minit_context_word_embs_model\u001b[1;34m(model_path, model_type, device, force_reload, batch_size, top_k, silence, use_custom_api)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRoberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bert'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model type value is unexpected. Only support bert and roberta models.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\nlpaug\\model\\lang_models\\bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, temperature, top_k, top_p, batch_size, device, silence)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMASK_TOKEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD_TOKEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1730\u001b[0m                         \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m                         \u001b[0muse_auth_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m                         \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m                     )\n\u001b[0;32m   1734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1927\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m             \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m         )\n\u001b[0;32m   1931\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   2122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2124\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2125\u001b[0m             \u001b[0m_raise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m             \u001b[0metag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X-Linked-Etag\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ETag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mhead\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'head'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                 )\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             \u001b[0mtls_in_tls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtls_in_tls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         )\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[1;32m--> 450\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m         )\n\u001b[0;32m    452\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         )\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m    868\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36624d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = augment_text(data[data['data_type']=='train'], samples=9540)\n",
    "data = data[data['data_type']!='train'] \n",
    "data = data.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d247be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['data_type'] = 'train'\n",
    "new['word_count'] = new['Comment'].str.split().str.len()\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b937bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['data_type']!='train'] \n",
    "data = data.append(new)\n",
    "data.to_csv('augmented_data_v0.1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cbc0e4",
   "metadata": {},
   "source": [
    "# Apply data augmentation - backtranslation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5634d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text_bt(df,sample_from, sample_to):\n",
    "    back_translation_aug = naw.BackTranslationAug(batch_size=1, device='cuda', max_length=512)\n",
    "\n",
    "    new_text=[]\n",
    "    sample_label=[]\n",
    "    translated_from_id=[]\n",
    "\n",
    "    ori_df = df\n",
    "\n",
    "    ## data augmentation loop\n",
    "    for i in tqdm(range(sample_from,sample_to)):\n",
    "#         try:\n",
    "            \n",
    "            text = df.iloc[i]['Comment']\n",
    "            label = df.iloc[i]['Outcome']\n",
    "            train_id = df.iloc[i]['train_id']\n",
    "            if len(text) <= 1028:\n",
    "                augmented_text = back_translation_aug.augment(text)\n",
    "\n",
    "    #             print(train_id)\n",
    "                print(text)\n",
    "                print()\n",
    "    #             print(augmented_text)\n",
    "                new_text.append(augmented_text)\n",
    "                sample_label.append(label)\n",
    "                translated_from_id.append(train_id)\n",
    "\n",
    "                if (i+1)%100==0:\n",
    "                    ## dataframe\n",
    "                    new=pd.DataFrame({'Comment':new_text,'Outcome':sample_label})\n",
    "                    new['Outcome'] = new['Outcome'].astype(int)\n",
    "                    new['data_type'] = 'train'\n",
    "                    new['translated_from'] = translated_from_id\n",
    "                    new['batch'] = 1\n",
    "                    augmented_df=ori_df.append(new)\n",
    "\n",
    "                    augmented_df.to_csv('augmented_train_data_bt_1-' + str(i+1) + ' v0.1.csv', index=False)\n",
    "            else:\n",
    "                continue\n",
    "#         except:\n",
    "#             pass\n",
    "                \n",
    "    return augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac721b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('augmented_train_data_bt_1-20700 v0.1.csv')\n",
    "augmented_train_data_bt = augment_text_bt(data_train, sample_from = 20700, sample_to = 30000)\n",
    "augmented_train_data_bt.to_csv('augmented_train_data_bt_1-30000 v0.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4448ac",
   "metadata": {},
   "source": [
    "# Read augmented data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fed043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3524: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('augmented_data_v0.1.csv')\n",
    "\n",
    "# data_train = pd.read_csv('augmented_train_data_bt_1-35559 v0.1.csv')[0:48067]\n",
    "data_train = pd.read_csv('augmented_train_data_bt_1-13500_30000-40000v0.2.csv')\n",
    "data_train = data_train.dropna(subset=['Comment','Outcome'])\n",
    "data_train['Outcome'] = data_train['Outcome'].astype('int64')\n",
    "\n",
    "data_val = pd.read_csv('val_data_v0.1.csv')\n",
    "data_val = data_val.dropna(subset=['Comment','Outcome'])\n",
    "data_val['Outcome'] = data_val['Outcome'].astype('int64')\n",
    "\n",
    "data = data_train.append(data_val)\n",
    "\n",
    "data_test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59714db",
   "metadata": {},
   "source": [
    "# Text preprocessing (not used in final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a3c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Qwerty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_text(x):\n",
    "#     x = BeautifulSoup(x, \"lxml\").text\n",
    "#     x = \" \".join(word for word in x.split() if word not in STOPWORDS)\n",
    "#     x = \" \".join(x.lower() for x in x.split())\n",
    "#     x = x.replace('[^\\w\\s]', '')\n",
    "#     x = re.sub(r'\\d+', '1', x)\n",
    "#     return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68a76ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://stackoverflow.com/questions/1/bs1-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste hello 1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"https://stackoverflow.com/questions/24398302/bs4-featurenotfound-couldnt-find-a-tree-builder-with-the-features-you-requeste hello this is 78678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa3bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\bs4\\__init__.py:438: MarkupResemblesLocatorWarning: \"http://pypi.python.org/pypi/ghostscript/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\bs4\\__init__.py:438: MarkupResemblesLocatorWarning: \"http://www.devpro.it/json/files/json-js.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\bs4\\__init__.py:438: MarkupResemblesLocatorWarning: \"http://mail.scipy.org/pipermail/scipy-user/2010-january/023847.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\bs4\\__init__.py:438: MarkupResemblesLocatorWarning: \"http://en.wikipedia.org/wiki/floating_point#accuracy_problems\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "# data_train['Comment'] = data_train['Comment'].apply(clean_text)\n",
    "\n",
    "\n",
    "# data_val['Comment'] = data_val['Comment'].apply(clean_text)\n",
    "\n",
    "\n",
    "# data_test['Comment'] = data_test['Comment'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df407ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b57deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>data_type</th>\n",
       "      <th>translated_from</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>numpy scipy available (and manipulating large ...</td>\n",
       "      <td>1</td>\n",
       "      <td>48267.0</td>\n",
       "      <td>122</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>iam performs process, larger list, like : list...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>problem: 1-bit python, 1-bit installer. cause ...</td>\n",
       "      <td>1</td>\n",
       "      <td>25241.0</td>\n",
       "      <td>221</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>try using eval convert string type, e.g. coord...</td>\n",
       "      <td>0</td>\n",
       "      <td>7024.0</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>updated wtforms 1.1 wtforms 1.1 (december 1) s...</td>\n",
       "      <td>1</td>\n",
       "      <td>28282.0</td>\n",
       "      <td>93</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67157</th>\n",
       "      <td>67154.0</td>\n",
       "      <td>here example implementation mystring = \"\\ n. j...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>35595.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67158</th>\n",
       "      <td>67155.0</td>\n",
       "      <td>if offer us library function find diagonal, i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>35596.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67159</th>\n",
       "      <td>67156.0</td>\n",
       "      <td>exponential moving averages use ratio. ratio a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>35597.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67160</th>\n",
       "      <td>67157.0</td>\n",
       "      <td>python 1.1 format: gzip open (\"path / / file,\"...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>35598.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67161</th>\n",
       "      <td>67158.0</td>\n",
       "      <td>likely signature invalid. you follow oauth spe...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>35599.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67151 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_id                                            Comment  Outcome  \\\n",
       "0           1.0  numpy scipy available (and manipulating large ...        1   \n",
       "1           2.0  iam performs process, larger list, like : list...        0   \n",
       "2           3.0  problem: 1-bit python, 1-bit installer. cause ...        1   \n",
       "3           4.0  try using eval convert string type, e.g. coord...        0   \n",
       "4           5.0  updated wtforms 1.1 wtforms 1.1 (december 1) s...        1   \n",
       "...         ...                                                ...      ...   \n",
       "67157   67154.0  here example implementation mystring = \"\\ n. j...        0   \n",
       "67158   67155.0  if offer us library function find diagonal, i ...        0   \n",
       "67159   67156.0  exponential moving averages use ratio. ratio a...        0   \n",
       "67160   67157.0  python 1.1 format: gzip open (\"path / / file,\"...        1   \n",
       "67161   67158.0  likely signature invalid. you follow oauth spe...        0   \n",
       "\n",
       "            Id word_count data_type  translated_from  batch  \n",
       "0      48267.0        122     train              NaN    NaN  \n",
       "1          NaN        172     train              NaN    NaN  \n",
       "2      25241.0        221     train              NaN    NaN  \n",
       "3       7024.0         40     train              NaN    NaN  \n",
       "4      28282.0         93     train              NaN    NaN  \n",
       "...        ...        ...       ...              ...    ...  \n",
       "67157      NaN        NaN     train          35595.0    1.0  \n",
       "67158      NaN        NaN     train          35596.0    1.0  \n",
       "67159      NaN        NaN     train          35597.0    1.0  \n",
       "67160      NaN        NaN     train          35598.0    1.0  \n",
       "67161      NaN        NaN     train          35599.0    1.0  \n",
       "\n",
       "[67151 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d64af",
   "metadata": {},
   "source": [
    "# Apply tokenization and data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9502a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer, BertForSequenceClassification, RobertaTokenizerFast, RobertaForSequenceClassification, AlbertTokenizer, AlbertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', do_lower_case=True, max_length = max_length)\n",
    "# tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc5c8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data['data_type']=='train']\n",
    "data_val = data[data['data_type']=='val']\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "#     data['Comment'].values.tolist(), \n",
    "    data_train['Comment'].values.tolist(),\n",
    "    \n",
    "#     add_special_tokens=True, \n",
    "    add_special_tokens=False, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    data_val['Comment'].values.tolist(), \n",
    "    \n",
    "#     add_special_tokens=True, \n",
    "    add_special_tokens=False, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# encoded_data_test = tokenizer.batch_encode_plus(\n",
    "#     data_test['Comment'].values.tolist(), \n",
    "    \n",
    "# #     add_special_tokens=True,\n",
    "#     add_special_tokens=False, \n",
    "#     return_attention_mask=True, \n",
    "#     pad_to_max_length=True, \n",
    "#     max_length=max_length, \n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(data_train['Outcome'].values)\n",
    "# labels_train = torch.tensor(data['Outcome'].values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(data_val['Outcome'].values)\n",
    "\n",
    "# input_ids_test = encoded_data_test['input_ids']\n",
    "# attention_masks_test = encoded_data_test['attention_mask']\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "# dataset_test = TensorDataset(input_ids_test, attention_masks_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2ad33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df0c2ff",
   "metadata": {},
   "source": [
    "# Load pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7c963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "#                                                       num_labels=2,\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\",\n",
    "#                                                       num_labels=2,\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
    "                                                      num_labels=6,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "# model = AlbertForSequenceClassification.from_pretrained('albert-base-v2',\n",
    "#                                                       num_labels=2,\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bac03",
   "metadata": {},
   "source": [
    "# Load train and validation data into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9409b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "# dataloader_test = DataLoader(dataset_test, \n",
    "#                                    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3467c",
   "metadata": {},
   "source": [
    "# Configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab15ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\qwerty\\desktop\\documents\\nus\\bt 5153 applied machine learning for business anlaytics\\bk_env37\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb667a6",
   "metadata": {},
   "source": [
    "# Configure scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f539f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739b34b",
   "metadata": {},
   "source": [
    "# Check for cuda status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab8adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "        \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d713bf",
   "metadata": {},
   "source": [
    "# Define function for evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c867f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "        \n",
    "            \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "def predict(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "#         loss = outputs[0]\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        \n",
    "            \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbcb72f4",
   "metadata": {},
   "source": [
    "# Define performance metrics for evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "432b3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def confusion_matrix_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return confusion_matrix(labels_flat, preds_flat)\n",
    "    \n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def f1_score_macro_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='macro')\n",
    "\n",
    "def accuracy_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "#     label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "#         print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Class: {label}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dccd3d",
   "metadata": {},
   "source": [
    "# Perform model training + save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e86cae8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89867021caa14a17b3433308d1c51f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.5289610033294114\n",
      "Validation loss: 0.4565538260908241\n",
      "F1 Score (Weighted): 0.854079546897085\n",
      "Accuracy: 0.8565347226634474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.42014323036447965\n",
      "Validation loss: 0.5070242911448999\n",
      "F1 Score (Weighted): 0.8666698740030425\n",
      "Accuracy: 0.8677806722155156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.3776705145503607\n",
      "Validation loss: 0.5234793405370325\n",
      "F1 Score (Weighted): 0.8714814227224362\n",
      "Accuracy: 0.8732448058961815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.32530014357242404\n",
      "Validation loss: 0.5946864933770498\n",
      "F1 Score (Weighted): 0.8700349484107748\n",
      "Accuracy: 0.8724823686384141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.28363006130646845\n",
      "Validation loss: 0.6506882102086631\n",
      "F1 Score (Weighted): 0.8692506716471704\n",
      "Accuracy: 0.8708304212465849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
    "#                                                       num_labels=2,\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n",
    "# model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('model6/finetuned_RoBERTa_epoch_1.model', map_location=torch.device(device)))\n",
    "\n",
    "start = 1\n",
    "for epoch in tqdm(range(start, epochs+start)):\n",
    "    \n",
    "    # move model to cuda\n",
    "    model.cuda()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "               \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }        \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "          \n",
    "        \n",
    "    torch.save(model.state_dict(), f'model1/finetuned_roberta_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    accuracy = accuracy_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    tqdm.write(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6c884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.28363006130646845\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27248\\3315678144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training loss: {loss_train_avg}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mval_macro_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score_macro_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27248\\4014360489.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(dataloader_val)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         inputs = {'input_ids':      batch[0],\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27248\\4014360489.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         inputs = {'input_ids':      batch[0],\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    val_macro_f1 = f1_score_macro_func(predictions, true_vals)\n",
    "    accuracy = accuracy_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    tqdm.write(f'F1 Score (Macro): {val_f1_macro}')\n",
    "    tqdm.write(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97c76bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5234793405370325\n",
      "F1 Score (Weighted): 0.8714814227224362\n",
      "Accuracy: 0.8732448058961815\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
    "                                                      num_labels=6,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model1/finetuned_RoBERTa_epoch_3.model', map_location=torch.device(device)))\n",
    "\n",
    "val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "val_f1 = f1_score_func(predictions, true_vals)   \n",
    "accuracy = accuracy_func(predictions, true_vals)\n",
    "tqdm.write(f'Validation loss: {val_loss}')\n",
    "tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "tqdm.write(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dfe47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65      2622\n",
      "           1       0.89      0.89      0.89      2631\n",
      "           2       0.97      0.96      0.96      2639\n",
      "           3       0.67      0.86      0.75      2582\n",
      "           4       0.99      0.98      0.98      2638\n",
      "           5       0.98      0.98      0.98      2627\n",
      "\n",
      "    accuracy                           0.87     15739\n",
      "   macro avg       0.88      0.87      0.87     15739\n",
      "weighted avg       0.88      0.87      0.87     15739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Classification Report:\\n',classification_report(true_vals, np.argmax(predictions, axis=1).flatten())) ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47ff51",
   "metadata": {},
   "source": [
    "# Load model + perform final prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "#                                                       num_labels=2,\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('model2/finetuned_BERT_epoch_2.model', map_location=torch.device(device)))\n",
    "\n",
    "# predictions = predict(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f6dfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
    "                                                      num_labels=2,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model11/finetuned_roberta_epoch_2.model', map_location=torch.device(device)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749f9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13cea9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec7ce939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b9c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Outcome'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b31d020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Id</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clearly i should have worked on this for anoth...</td>\n",
       "      <td>57525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in most cases r is an interpreted language tha...</td>\n",
       "      <td>62692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>most of the algorithms for eigen value computa...</td>\n",
       "      <td>54789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you're willing to entertain an alternate pl...</td>\n",
       "      <td>61455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>try littler. littler provides hash-bang (i.e. ...</td>\n",
       "      <td>78000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>either (setq ess-fancy-comments nil) if you ne...</td>\n",
       "      <td>78362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>use '###' if you don't want the comments inden...</td>\n",
       "      <td>61974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you don't need the two lines: scale &lt;- data[1]...</td>\n",
       "      <td>58798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i used the same reference (bryan o'sullivan's ...</td>\n",
       "      <td>61000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>here's one way by using a closure (in the prog...</td>\n",
       "      <td>66369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>r lists can be thought of as hashes- vectors o...</td>\n",
       "      <td>78752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>actually the following works for me: write(\"pr...</td>\n",
       "      <td>68684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>first of all, the plot.svm function assumes th...</td>\n",
       "      <td>71471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>using base graphics, the standard way to do th...</td>\n",
       "      <td>65352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i use the \"r\" command with the standard r.app ...</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>matrix is the most common and has also just be...</td>\n",
       "      <td>50914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>both the match() (returns the first appearance...</td>\n",
       "      <td>71807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>this is one way to do it. first i get the indi...</td>\n",
       "      <td>74301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the r language definition is handy for answeri...</td>\n",
       "      <td>72291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>double brackets accesses a list element, while...</td>\n",
       "      <td>66474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[] extracts a list, [[]] extracts elements wit...</td>\n",
       "      <td>73096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>look at the package sqldf. http://code.google....</td>\n",
       "      <td>55411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>here's one way using the lme4 package. &gt; libra...</td>\n",
       "      <td>76262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mark bravington's debugger which is available ...</td>\n",
       "      <td>66170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i usually start out with some combination of: ...</td>\n",
       "      <td>73606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>just the first part of that question can fill ...</td>\n",
       "      <td>57528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>alternatively, you can use the kernlab package...</td>\n",
       "      <td>71226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>one approach is to just add the column to the ...</td>\n",
       "      <td>58394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>str(x) it's all you need to remember for 99% o...</td>\n",
       "      <td>66160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>if you don't want this behaviour, don't use fa...</td>\n",
       "      <td>63794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>here's another way, which i believe is equival...</td>\n",
       "      <td>58679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>here's an approach using the plyr package: d &lt;...</td>\n",
       "      <td>78215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>no, but you can write it yourself: q &lt;- functi...</td>\n",
       "      <td>68334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dan goldstein provides a search engine for r t...</td>\n",
       "      <td>70604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>use one post per main question. as the first a...</td>\n",
       "      <td>51978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>first off, a lot of that 'loops are bad' chatt...</td>\n",
       "      <td>73648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>properly formatted your data looks like this 8...</td>\n",
       "      <td>50037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>using the reshape package you can do something...</td>\n",
       "      <td>77657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the following code has served me well. customi...</td>\n",
       "      <td>76518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>the dput command writes an ascii representatio...</td>\n",
       "      <td>50886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i agree with dirk advice! imho, organizing you...</td>\n",
       "      <td>75410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>this might sound a little obvious especially i...</td>\n",
       "      <td>56820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>memory for deleted objects is not released imm...</td>\n",
       "      <td>73274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>you do that in the device, e.g. x11(width=4, h...</td>\n",
       "      <td>65821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>my concise answer: write your functions carefu...</td>\n",
       "      <td>72190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>with this (very helpful) function by kevin wri...</td>\n",
       "      <td>79240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>there are some good examples of doing this ove...</td>\n",
       "      <td>56582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>alternatively, using the package deducer libra...</td>\n",
       "      <td>54130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>i have looked at r's src/library/stats/src/tru...</td>\n",
       "      <td>65219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i much prefer to use with to obtain the equiva...</td>\n",
       "      <td>79330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>i never use attach. with and within are your f...</td>\n",
       "      <td>65750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>you can achieve this using the built-in embed(...</td>\n",
       "      <td>53354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i like putting different functionality in thei...</td>\n",
       "      <td>79954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>not straightforward, but it works: &gt; t(sapply(...</td>\n",
       "      <td>56539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>the documentation for ifelse states: ifelse re...</td>\n",
       "      <td>75497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>you can use apply (or sapply) t &lt;- c(\"bob_smit...</td>\n",
       "      <td>55151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>how about: tlist &lt;- c(\"bob_smith\",\"mary_jane\",...</td>\n",
       "      <td>66744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ensure you record your work in a reproducible ...</td>\n",
       "      <td>71129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>that's a good trick. one other suggestion is t...</td>\n",
       "      <td>77976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>i never save an r workspace. i use import scri...</td>\n",
       "      <td>64920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>to further illustrate the common strategy of f...</td>\n",
       "      <td>76296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>try using ggplot2: dnow &lt;- read.table(\"http://...</td>\n",
       "      <td>76582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>a few other r users i talked to use a 'one-dir...</td>\n",
       "      <td>50612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>the ultimate reason is that if you do both gen...</td>\n",
       "      <td>60717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>first, convert the london time to a posixct ob...</td>\n",
       "      <td>53601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>the effects package has good ploting methods f...</td>\n",
       "      <td>63362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>use the serialization feature to turn any r ob...</td>\n",
       "      <td>75121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>from: http://gking.harvard.edu/zelig/docs/how_...</td>\n",
       "      <td>60879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>another choice is use the ddply function from ...</td>\n",
       "      <td>59995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>here's one possibility with the ggplot2 packag...</td>\n",
       "      <td>64104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>the cran task view on high-performance comptin...</td>\n",
       "      <td>52127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>not sure i understand. appending to same file ...</td>\n",
       "      <td>70499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>did you look at help(pdf) ? usage: pdf(file = ...</td>\n",
       "      <td>54492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>you can generate tikz code from r: http://r-fo...</td>\n",
       "      <td>77565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>this seems to work: &gt; groupacres &lt;- ddply(myda...</td>\n",
       "      <td>77596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i think you want to first suppress the labels ...</td>\n",
       "      <td>53948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>if you wrap your inner function with a try() s...</td>\n",
       "      <td>63050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>check out the ggplot documentation for scale_b...</td>\n",
       "      <td>75136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>here's a small dataset: dat &lt;- data.frame(x=1:...</td>\n",
       "      <td>54412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>you should copy shortcut to r (r.lnk file) to ...</td>\n",
       "      <td>56733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>a step-by-step tutorial to this kind of plotti...</td>\n",
       "      <td>61525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>library(rcurl) library(xml) # download page us...</td>\n",
       "      <td>52150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>another option using xpath. library(rcurl) lib...</td>\n",
       "      <td>73796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>i seem to recall that plain old split() has a ...</td>\n",
       "      <td>65836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>you can use grep() with colnames(): survey[,gr...</td>\n",
       "      <td>76962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>as a more general solution, you can use the ca...</td>\n",
       "      <td>62543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>you can do this with by(). first set up some d...</td>\n",
       "      <td>66002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>given the format you want for the result, the ...</td>\n",
       "      <td>54046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>just for completeness, you have two more optio...</td>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>as pointed out here, there's an easy way to do...</td>\n",
       "      <td>77889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>here's an example using ggplot2: q &lt;- qplot(ct...</td>\n",
       "      <td>72316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>yes, there is: ess. and it is very highly reco...</td>\n",
       "      <td>61885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>&gt; summary(assayaov)[1][[1]][[1]][[3]] [1] 15.4...</td>\n",
       "      <td>67485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>i agree with the other responders: sweave is e...</td>\n",
       "      <td>70250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>if you'd like to see some examples, i have a f...</td>\n",
       "      <td>64391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>the first plot was just covered in a blog post...</td>\n",
       "      <td>78902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>i generally break my projects into 4 pieces: l...</td>\n",
       "      <td>77398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>from pinheiro &amp; bates 2000, section 5.4, p250:...</td>\n",
       "      <td>60802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>my thought process for finding function code t...</td>\n",
       "      <td>76715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i agree with dirk, it's hard. i would recomend...</td>\n",
       "      <td>52408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment     Id  Outcome\n",
       "0   clearly i should have worked on this for anoth...  57525        1\n",
       "1   in most cases r is an interpreted language tha...  62692        1\n",
       "2   most of the algorithms for eigen value computa...  54789        1\n",
       "3   if you're willing to entertain an alternate pl...  61455        1\n",
       "4   try littler. littler provides hash-bang (i.e. ...  78000        1\n",
       "5   either (setq ess-fancy-comments nil) if you ne...  78362        1\n",
       "6   use '###' if you don't want the comments inden...  61974        1\n",
       "7   you don't need the two lines: scale <- data[1]...  58798        1\n",
       "8   i used the same reference (bryan o'sullivan's ...  61000        1\n",
       "9   here's one way by using a closure (in the prog...  66369        1\n",
       "10  r lists can be thought of as hashes- vectors o...  78752        1\n",
       "11  actually the following works for me: write(\"pr...  68684        1\n",
       "12  first of all, the plot.svm function assumes th...  71471        0\n",
       "13  using base graphics, the standard way to do th...  65352        1\n",
       "14  i use the \"r\" command with the standard r.app ...  65536        1\n",
       "15  matrix is the most common and has also just be...  50914        1\n",
       "16  both the match() (returns the first appearance...  71807        1\n",
       "17  this is one way to do it. first i get the indi...  74301        1\n",
       "18  the r language definition is handy for answeri...  72291        1\n",
       "19  double brackets accesses a list element, while...  66474        1\n",
       "20  [] extracts a list, [[]] extracts elements wit...  73096        1\n",
       "21  look at the package sqldf. http://code.google....  55411        0\n",
       "22  here's one way using the lme4 package. > libra...  76262        1\n",
       "23  mark bravington's debugger which is available ...  66170        1\n",
       "24  i usually start out with some combination of: ...  73606        1\n",
       "25  just the first part of that question can fill ...  57528        1\n",
       "26  alternatively, you can use the kernlab package...  71226        1\n",
       "27  one approach is to just add the column to the ...  58394        1\n",
       "28  str(x) it's all you need to remember for 99% o...  66160        1\n",
       "29  if you don't want this behaviour, don't use fa...  63794        1\n",
       "30  here's another way, which i believe is equival...  58679        1\n",
       "31  here's an approach using the plyr package: d <...  78215        1\n",
       "32  no, but you can write it yourself: q <- functi...  68334        1\n",
       "33  dan goldstein provides a search engine for r t...  70604        1\n",
       "34  use one post per main question. as the first a...  51978        1\n",
       "35  first off, a lot of that 'loops are bad' chatt...  73648        1\n",
       "36  properly formatted your data looks like this 8...  50037        1\n",
       "37  using the reshape package you can do something...  77657        1\n",
       "38  the following code has served me well. customi...  76518        0\n",
       "39  the dput command writes an ascii representatio...  50886        1\n",
       "40  i agree with dirk advice! imho, organizing you...  75410        0\n",
       "41  this might sound a little obvious especially i...  56820        1\n",
       "42  memory for deleted objects is not released imm...  73274        1\n",
       "43  you do that in the device, e.g. x11(width=4, h...  65821        1\n",
       "44  my concise answer: write your functions carefu...  72190        1\n",
       "45  with this (very helpful) function by kevin wri...  79240        1\n",
       "46  there are some good examples of doing this ove...  56582        1\n",
       "47  alternatively, using the package deducer libra...  54130        1\n",
       "48  i have looked at r's src/library/stats/src/tru...  65219        1\n",
       "49  i much prefer to use with to obtain the equiva...  79330        1\n",
       "50  i never use attach. with and within are your f...  65750        1\n",
       "51  you can achieve this using the built-in embed(...  53354        1\n",
       "52  i like putting different functionality in thei...  79954        1\n",
       "53  not straightforward, but it works: > t(sapply(...  56539        1\n",
       "54  the documentation for ifelse states: ifelse re...  75497        1\n",
       "55  you can use apply (or sapply) t <- c(\"bob_smit...  55151        1\n",
       "56  how about: tlist <- c(\"bob_smith\",\"mary_jane\",...  66744        1\n",
       "57  ensure you record your work in a reproducible ...  71129        1\n",
       "58  that's a good trick. one other suggestion is t...  77976        1\n",
       "59  i never save an r workspace. i use import scri...  64920        0\n",
       "60  to further illustrate the common strategy of f...  76296        1\n",
       "61  try using ggplot2: dnow <- read.table(\"http://...  76582        1\n",
       "62  a few other r users i talked to use a 'one-dir...  50612        1\n",
       "63  the ultimate reason is that if you do both gen...  60717        1\n",
       "64  first, convert the london time to a posixct ob...  53601        1\n",
       "65  the effects package has good ploting methods f...  63362        1\n",
       "66  use the serialization feature to turn any r ob...  75121        1\n",
       "67  from: http://gking.harvard.edu/zelig/docs/how_...  60879        1\n",
       "68  another choice is use the ddply function from ...  59995        1\n",
       "69  here's one possibility with the ggplot2 packag...  64104        1\n",
       "70  the cran task view on high-performance comptin...  52127        1\n",
       "71  not sure i understand. appending to same file ...  70499        0\n",
       "72  did you look at help(pdf) ? usage: pdf(file = ...  54492        1\n",
       "73  you can generate tikz code from r: http://r-fo...  77565        0\n",
       "74  this seems to work: > groupacres <- ddply(myda...  77596        1\n",
       "75  i think you want to first suppress the labels ...  53948        1\n",
       "76  if you wrap your inner function with a try() s...  63050        1\n",
       "77  check out the ggplot documentation for scale_b...  75136        1\n",
       "78  here's a small dataset: dat <- data.frame(x=1:...  54412        1\n",
       "79  you should copy shortcut to r (r.lnk file) to ...  56733        1\n",
       "80  a step-by-step tutorial to this kind of plotti...  61525        1\n",
       "81  library(rcurl) library(xml) # download page us...  52150        0\n",
       "82  another option using xpath. library(rcurl) lib...  73796        0\n",
       "83  i seem to recall that plain old split() has a ...  65836        1\n",
       "84  you can use grep() with colnames(): survey[,gr...  76962        1\n",
       "85  as a more general solution, you can use the ca...  62543        1\n",
       "86  you can do this with by(). first set up some d...  66002        1\n",
       "87  given the format you want for the result, the ...  54046        1\n",
       "88  just for completeness, you have two more optio...  50003        1\n",
       "89  as pointed out here, there's an easy way to do...  77889        1\n",
       "90  here's an example using ggplot2: q <- qplot(ct...  72316        1\n",
       "91  yes, there is: ess. and it is very highly reco...  61885        1\n",
       "92  > summary(assayaov)[1][[1]][[1]][[3]] [1] 15.4...  67485        1\n",
       "93  i agree with the other responders: sweave is e...  70250        1\n",
       "94  if you'd like to see some examples, i have a f...  64391        1\n",
       "95  the first plot was just covered in a blog post...  78902        1\n",
       "96  i generally break my projects into 4 pieces: l...  77398        1\n",
       "97  from pinheiro & bates 2000, section 5.4, p250:...  60802        1\n",
       "98  my thought process for finding function code t...  76715        1\n",
       "99  i agree with dirk, it's hard. i would recomend...  52408        0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "data_test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a54b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_test[['Id', 'Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7068478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28858</th>\n",
       "      <td>53750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28859</th>\n",
       "      <td>56455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28860</th>\n",
       "      <td>78034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28861</th>\n",
       "      <td>62237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28862</th>\n",
       "      <td>55230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Outcome\n",
       "0      57525        1\n",
       "1      62692        1\n",
       "2      54789        1\n",
       "3      61455        1\n",
       "4      78000        1\n",
       "...      ...      ...\n",
       "28858  53750        1\n",
       "28859  56455        1\n",
       "28860  78034        1\n",
       "28861  62237        1\n",
       "28862  55230        1\n",
       "\n",
       "[28863 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce034777",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('submission_14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bef57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
